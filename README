=========================== DESCRIPTION ===================================
(*) this project was realized with the following two goals in mind:
	1) familiarize myself with the Java Threads API.
	2) obtain a better understanding of how document processing on a
	large scale is done, using the Map-Reduce paradigm.

(*) with the above goals in mind, what this project does is it processes
some documents in order to obtain a result which was communicated to us
by the TA team. This is done using a personal, somewhat generic Map-Reduce
paradigm implementation and, of course, using a multithreaded approach.
===========================================================================

=========================== CLASS DETAILS =================================
(*) Mapper, Reducer
	- interfaces which assure the generic character of the map and
	reduce operations.

(*) Collector
	- interface implemented by the objects which will store the
	information from the map and reduce operations
	- the classes implementing this interface should be some kind of
	wrappers over containers (especially Maps)
(*) Text
	- interface which assures the generic character of the values
	from the operations in Map

(*) FileEntry
	- this class is used as a key in map() and reduce() because,
	before the output is written, it needs to be sorted and if two
	files have the same rank, then there needs to be made some kind
	of differentiation between them using the positions they have
	in the input file so it wouldn't have been enough to just use
	the file names as the keys.	
===========================================================================

=============================== WORKFLOW ==================================
(*) STEPS:
	1) The files are fragmented into pieces of size D (if possible)
	
	2) A map() task is prepared for each fragment resulting from 1)
	and is assigned to a worker using the ExecutorService model.
	Before going to the next step, all tasks need to be executed.

	3) A reduce() task is prepared for each entry in the Collector
	object produced by step 2) and is assigned to a worker. Before
	going to the next step, all tasks need to be executed.

	4) Before printing the output, the results from step 3) are sorted
	using the rank and the index of the input file if need be.
===========================================================================

========================= ADDITIONAL COMMENTS ============================
(*) to make sure that a fragment doesn't start in the middle of a word,
the offset value is adjusted such that when a character is read from the
offset value, that character will be the beginning of a word.

(*) to make sure that a fragment doesn't end in the middle of a word,
the size value is adjusted such that when a character is read from that
value, that character will be the ending of a word.

(*) in order to avoid race conditions I used thread-safe data structures
where it was required (exception: in collect() from MapOutput I had to use
a lock on the list to make sure that it's not being modified by another
thread while it's being updated)
===========================================================================

